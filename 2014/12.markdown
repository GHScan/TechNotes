#### 23. Engineering a compiler. 第1章，编译概观
+ 简介
    + 编译器是一种工具，它将一种语言翻译到另一种语言，因此，它需要了解源语言的语法和语义(对应前端)，以及目标语言的语法和语义(对应后端)
    + 对比
        + 编译器：输入源语言，输出目标语言
        + 解释器：输入源语言，输出结果(尽管内部可能有编译等动作)
        + 虚拟机：输入目标语言，输出结果
    + 基本规则
        1. 必须保持语义
        2. 能以可观测的方式改进输入
    + 由于前端已经有成熟的O(n)算法了，所以编译器的开销主要在优化器和后端上
+ 转换概述
    + 前端
        + 词法分析：将字符串转化单词流
        + 语法分析：判断单词流是否是源语言的句子
        + 语义分析：类型检查等
    + 优化器
        + 数据流分析、相关性分析、转换等
    + 后端
        + 指令选择(instruction selection): 将IR转换为目标机操作。此时使用的可能是虚拟寄存器，即数量不限的寄存器符号。一般这里能用动态规划等手段
        + 寄存器分配(register allocation): 将虚拟寄存器换成物理寄存器。通常是贪心算法等
        + 指令调度(instruction scheduling): 根据数据依赖重排指令，调整emit时间，从而更高效的利用CPU流水线

#### 23. Engineering a compiler. 附录B, 数据结构
+ 集合
    + 适用通用ADT的Set：bst、hashtable、ordered array、ordered list
        + 对全集U的大小无限制，可以动态适应
    + 当元素能被表示成整数，且全集U大小固定时(即离线算法，比如编译器领域，前端parse源码过后，IR的规模已知，因此全集U大小固定)
        + ordered list(linked list): 适合集合容量S绝对数值较小时
        + bitset: 空间效率最高: 缺点是，因为foreach、intersect、union等操作都是O(U)的，所以，如果S总是远远小于U(稀疏)，则不划算
        + bitset+ordered list: member是O(1)，insert、delete是O(S)，foreach、intersect、union都是O(S)，效果介于纯ordered list/bitset之间
        + sparse set: 一个O(U)大的sparse数组存放dense数组的索引，加上一个O(S)大的dense数组存放sparse索引，以及一个标量next
            + 优点1：无需初始化，或者说，初始化及clear都是O(1)的：next = 0
            + 优点2：insert、delete是O(1)的，而bitset+ordered list是O(S)的，类似S=10^3、U=10^6的时候，很合适
            + member的实现：0 <= sparse[i] < next && dense[sparse[i]] == i
            + insert的实现：sparse[i] = next; dense[next++] = i;
            + delete的实现：j = dense[next - 1]; dense[sparse[i]] = j; dense[sparse[j]] = i; swap(sparse[i], sparse[j]); --next
            + foreach的实现：for (i<-dense[0:next]) {...}
+ IR的表示
    + 图
        + 树
            + 所有使用指针的地方，都可以等价的换成数组索引，前提是IR规模已知(恰好编译器大部分算法是离线算法，满足这个条件)
                + 分配快速（除非指针方案的内存池做得够好）
                + 内存局部性更好
                + 可以直接进行块IO，而无需额外的一趟指针序列化
                + 便于调试
                + 数组索引相对指针更有利于编译器优化
            + 任何树都可以表示为二叉树，从而高效的分配、释放节点；当子节点数可变时，尤为有效
                + 如 `struct Node{ T value; LinkedList<Node*> children; }`, 其sizeof大致等于sizeof(T) + sizeof(void*)，即使子节点数可变，依然可高效分配
        + 有向图
            + 同样可以表达为二叉树
                + 如 `struct Node { T value; LinkedList<Node*> outEdges; }`
            + 可以配置额外的vector<Node*>来加速某些访问
        + 无向图
            + 密集图，考虑使用下三角的bit矩阵
            + 稀疏图，可以使用`hashtable<tuple<Node*, Node*>>`等
    + 线性
        + 数组
            + 优点是空间局部性好，直接块IO等
            + 缺点是插入、删除效率低。但IR数组不同于普通数据数组，它能借助detour运算符(类似于jump指令？)，通过类似memory patch的方式引入out-of-line代码，从而高效的增删IR数组
                + 最后需要在每个pass末尾，或者detour超过一定次数后，重新数组数组，对所有的detour操作进行线性化(inline?)
        + 链表
            + 高效的insert/delete
            + 空间局部性差(用内存池弥补，尤其是IR规模U已知的条件下...)
            + 指针相比数组，对编译器优化分析更困难
+ 哈希表
    + hash表的关键在于散列函数和碰撞处理
        + Knuth提出了一个简单的乘法散列函数：`h(key) = tableSize * ((C * key) mod 1)`，一个建议的C值是0.618((sqrt(5) - 1) / 2)
    + 开放散列法(open hashing)
        + 缺点及对策:
            1. 内存分配瓶颈 => free list的内存池
            2. 链表过长 => 通过rehash使得U/S足够大
        + 在每次访问后，还可以选择将项往前移1，或者直接提到开头
    + 开放地址法(open addressing)
        + 缺点
            1. 当U/S接近1的时候，性能急剧下降，需要rehash
        + 两种选择的内存占用
            1. bucket上面保存指针: 相比open hashing，少了linkedList的next指针，总内存占用可能更少
            2. bucket上面保存key/value的entry: 虽然少了一层指针的间接层，但由于有大量闲置entry，如果key/value的size明显大于指针，那么，有可能总内存更多；因此，这种嵌入的存储，主要适合小对象
+ 符号表
    + 符号表被用于编译期(注意，不是运行时，运行时直接lexical addressing)，虽然可选的方案可以是ordered key/value list、balance bst、hashtable，但因为没有顺序遍历的要求，一般采用hashtable实现
    + 符号表虽然用hashtable实现，但它的行为更特殊，与其说是insert、member、delete，不如说是`push(key, value)`、`lookup(key)`、`pop()`这组接口，即，它的增删复合栈顺序，因此可以比普通hashtable更优化
        + 存储方面，由于增删的栈顺序，相比用free list，它可以进一步用栈分配器，而且真正的支持单个项的free
        + 通过一个栈来保存已分配元素，它能支持O(S)而非O(U)(这里的U指bucket项数)的遍历，而且有更好的局部性(栈顶访问更频繁)，甚至能块IO
        + rehash的时候，不需要同时保存新旧两个数组，直接旧数组resize后，反向遍历栈然后插入
        + 这里的栈为了提供稳定的项指针，可能实现为分段栈
    + scoped symbol table(词法作用域的符号表)
        + 简单的做法是准备一个stack<hashtable>，这样，insert、delete都很快，但是lookup、update需要沿着栈逐个查找，更慢；实际的符号表是查找、修改更多，而增删很少，所以需要将开销分摊在pushScope、popScope、insert/delete上，进而提供O(1)的lookup/update
        + open hashing + stack allocator可以提供一个高效的scoped symbol table实现：
            + pushScope => ++currScope
            + push => buckets[h(key)] = new List(key, value, currScope, buckets[h(key)])
            + lookup => list = buckets[h(key)]; while (list != null && list.key != key); list.value
            + pop => node = stack.pop(); buckets[h(node.key)] = node.next
            + popScope => while (stack.top.scope == currScope) pop(); --currScope

#### 24. Engineering a compiler. 第2章，词法分析器
2. 识别单词
    + 要识别特定单词，可以通过嵌套O(K)层if/else来手工识别
    + 嵌套if/else的代码可以表示为状态迁移图，也就是所谓的FA(finite automation)
    + FA的形式化表示：
        1. 状态集合S(包括错误状态se)
        2. 输入字符集Z
        3. 转移函数f= (State,Char)=>State
        4. 开始状态s0
        5. 接受状态集合SA
    + 对于一个输入字符c，它至少会跳转至状态se，进入se后，FA将继续消耗整个输入
    + 通过将FA对应的识别代码，从嵌套if/else改为while循环，将转移函数f表达为查表，识别器可以支持无限集合
        + 有限的单词集合，可以用无环FA表达，无限集合，必须用有环FA(对应RE的闭包)
3. 正则表达式
    + FA在记法上太复杂，因此引入RE，而RE和FA等价，可以互相转换
    + RE的形式化定义
        1. RE描述定义在符号集Z以及空串上的语言
        2. 三个基本操作
            1. 连接
            2. 选择
            3. 克林闭包(Kleene closure)，记做*
                + 有限闭包(Finite closure)，记做Ri，如R5
                + 正闭包(Positive closure)，记做+。R+等价于RR*
    + (grep的全称`global regular expresion pattern match and print`)
    + 在定义程序语言的词法单元时，类似特定范围整数这样的模式，可以选择用简单的正则+后期处理，也可以直接用正则枚举。后者虽然会导致FA更复杂，生产过多状态、占用更多内存，但识别器本身仍然是O(n)的
    + RE的闭包性质，使得RE的各种处理算法仍然可以递归组合
    + RE的选择操作符，使得它可以描述任何一种有限集合的语言，只需枚举所有串并连接即可
    + RE的补集操作: 可以简单的将完整的FA的所有接受/非接受状态交换
    + 程序语言和自然语言在词法方面的一些区别：
        + 自然语言单词的拼写，和语义无关，而程序语言则尽量通过拼写来反应语法范畴(syntatic category)
        + 自然语言中，一个单词的词类，是上下文相关的，不同场合中会有不同的解释。程序语言中虽然曾经有这么做的(比如允许class作为identifier，即没有保留关键字的概念)，但新的语言已不再沿用该方案
4. 从正则表达式到词法分析器
    + 构造法循环：RE -(Thompson construction)-> NFA -(Subset construction)-> DFA -(Hopcroft算法, minimization)-> 最小化DFA -(Kleene construction)-> RE
        + 这同时也说明了RE、NFA、DFA等价
        + 给定一个语言(比如一个单词集合：0~31这32个数字)，可以反推出它的RE
    + 通过将输入字符集Char映射成CharCategory，可以显著控制输入规模
    + 之前的RE和FA没有使用空符号，而一旦引入它，用于连接多个FA，将导致出现非确定性转移，从而引入NFA
    + NFA(Nondeterministic finite automation)相比DFA(Deterministic finite automation)，有空转移符，以及非确定性转移
        + subset construction中，由一组状态move(c)得到的一组新状态，称为一个NFA配置(configuration of an NFA)，它对应一个DFA状态
            + 可以考虑用bitset实现
    + NFA、DFA等价性: 首先，NFA至少是DFA超集；又，任意NFA可以通过subset construction构造成DFA，所以二者等价
        + DFA状态数可能是NFA状态数的指数倍(2^N(Snfa))，因此，理论上它可能存在空间问题；但用它进行识别，仍然是O(N)的，没有时间问题
    + Thompson construction有几个性质可以用于简化实现
        + 每个状态最多只有两个输出边，最多两个输入边
            + 考虑表示成`struct NFAState{ int id; Tuple<Char, NFAState*> e1, e2;}`
    + Subset construction
        + 对每个状态n，可以离线计算e-closure{n}
            + 考虑表示成bitset
    + DFA minimization-Hopcroft算法
        + 是一种不动点应用，停止条件为，不可再split
        + 最小化之后，可以考虑再次进行CharCategory的压缩：当两个category在DFA table中的列完全相同时
    + 实现Scanner的时候，需要处理不同token的优先级，比如，new到底算关键字还是identifier
5. 实现词法分析器
    + 一些细节优化
        + 词素(lexeme)可以被hash，从而节省内存
            + 考虑用Symbol实现；同时也能加速后续symbol table访问的hashcode/equals性能
        + token本身可以被hash，从而各种单词素token可以共享内存
        + 特殊词素无需存储为字符串，可节省内存，比如float/int
            + 参照lex的做法，在token识别成功输出时，直接保存成int/float
        + 输入流为支持高效的readChar和rollback，可以考虑double buffer的block IO
    + 表驱动法分析器(table-driven scanners)
        + 固定的Scanner框架代码 + 语言特定的DFA table
            + 核心代码：`while (state != Se) { c = nextChar(); lexeme += c; state = table[state][category[c]]; }`
        + CharCategory的使用有利于减少DFA table的列数，从而有可能使得算法核心内存放入CPU cache
        + 最长匹配的贪婪策略可能引起的平方开销: 比如，以`a|a*b`匹配`aaaaa...`
            + 应对策略是，添加`Fail[State,InputPos]`的失败表，回滚的时候写表，而贪婪尝试的时候判断表项为空
    + 直接编码分析器(direct-coded scanners)
        + 每个状态用一个label表示，状态间转移，用goto来进行
        + 在状态中做category-based分派时，如果category对应单字符，那么可以直接用if；如果是连续的多字符，可以用if + range测试；简单的非连续字符，可以用switch；如果是复杂非连续的字符，仍然使用category table
            + 注意，当category对应的字符分布无规律时，switch可能慢于category table的lookup
        + 可以在生成各个状态代码时，根据状态特点来特化代码(相当于手工Scanner的部分好处)
    + 手工编码分析器(hand-coded scanners)
        + 可以做很多手工的细节优化
            + int的token，边识别，便进行输出值的累积`value = value * 10 + (c - '0')`
            + 单词素的token，识别过程中不必累积lexeme
            + 注释、空格/换行等，都不必累积lexeme
    + 关键字处理
        + 提供关键字RE
            + DFA状态数较多，适合table-driven scanner和direct-coded scanner
        + 使用identifier的RE，输出时查表判断是否是关键字，是的话输出对应token
            + DFA状态数较少，适合hand-coded scanner
            + 缺点是，每个identifier都要追加一次查表的额外开销
