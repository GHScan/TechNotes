#### 23. Engineering a compiler. 第3章，语法分析器
+ 简介
    + 语法分析的主要目的，是判断输入的单词流(每个单词都被标注成某个语法范畴(syntactic category))，是否是一个语法上有效的语句(sentence)。为了回答这个成员判定问题，我们首先需要一种形式化的方法描述语言。通过将语言限制到上下文无关语言这个集合，我们能够保证高效的回答这个判定问题。
    + 语法分析：对于形式文法(formal grammar)G，以及单词流s，词法分析要做的就是找到G生成语句s的一个推导
        + 推导应该无歧义。推导过程的graph描述，就是语法树(concrete syntax tree, parse tree)
        + 语法分析的输入是单词流，输出是推导(或者失败时的诊断信息)。如果不需要完整的推导信息(parse tree)，可以只输出抽象语法树(AST)，或者采用其他语义动作(semantic action)，直接进行解释
    + 总结：
        + 对于输入的单词流/字符流(如果没有经过Scanner的话)，语法分析尝试判定它是否是特定语言L(G)的成员。L(G)本身是无限集合，成员判定方法不明，通过将G限制为CFG，得到另一种高效的成员判断方法，即，在CFG中，能否找到唯一的一个推导，生成输入的句子。通过自底向上/自顶向下的parse，语法分析器输出错误，或者输出一个推导作为结果。推导的等价表示是具体语法树，一般不需要这样多的信息，而是输出AST，或者通过语义动作，输出其他属性值，比如表达式parse中，可以直接解释结果并返回。
+ 语法的表示
    + RE无法描述程序语言，因为它无法计数，只包含有限的状态
        + RE只是CFG的一个子集，对应产生式：A->a, A->a B
    + 我们需要比RE更强大的语言，同时具备高性能的特点。CFL正是传统的解决方案，尤其是的它的子集LR(1)、LL(1)，都能生成高效的识别器。
    + 术语(Glossary)
        + Context free grammar(上下文无关文法): 对于语言L，CFG定义了表示L中有效Sentence的集合
            + CFG的定义包括4个元素：T，NT，P，S，分别是终结符、非终结符、产生式、开始符号
        + Sentence(语句): 可以从grammar rules推导出的符号串(string of symbol)
        + Production(产生式): CFG中的每个规则(grammar rule)都称为一个产生式
        + Nonterminal symbol(非终结符): 是语法变量(syntactic variable)，用来进行抽象(abstraction)和表达结构(structure)
            + 正是因为NT的存在，CFG支持递归，进而比RE更强大
        + Terminal symbol(终结符): L(G)中单词的集合，对应Scanner输出的语法范畴(syntactic category)
        + Goal symbol/Start symbol(开始符号): 
        + Derivation(推导): 对开始符号，应用一系列重写(rewrite，选择产生式来替换非终结符)，得到语句的过程。
        + Sentential form(句型): 有效推导过程中出现的符号串(string of symbol)
            + 句型对应推导过程中部分完成的Parse tree的下边缘
        + Parse tree/Syntax tree(语法分析树/语法树)：A graph that represents a derivation
        + Leftmost derivation、Rightmost derivation(最左/最右推导): 一种推导，每次都重写最左/右的非终结符
        + Ambiguity(二义性): 如果L(G)中的某个句子有多个最左/最右推导，则说文法G具有二义性
    + CFG的层次结构，由大到小
        + 任意CFG：Earley算法可以在O(n^3)的时间内解析
        + LR(1): 从左到右扫描，右推导，允许lookahead一个单词
        + LL(1):
        + RG: 正则文法，和RE等价
+ 自顶向下语法分析(Top-down parsing)
    + 使用Topdown-parsing的时候，CFG的很大一个子集可以无需回溯的高效Parse——即Backtrack-free grammar(Predicate grammar)
    + Top-down parser需要消除左递归，否则将是死循环
        + 直接左递归(direct left recursion): 
            + 通过EBNF的star手法来消除
            + BNF中，实际上是：A->A b | c，改写为A -> c A2; A2->e | b A2
        + 间接左递归(indirect left recursion):
            + 使用消除循环引用的方法，即forward subsituation
            + 图算法：已知二维的有向图，先将每个节点编码成数字，于是，有向边分别指向左和右。我们通过消除指向左边的边，来使得引用总是从i指向i+1或更大，从而避免循环引用。
                1. 当i==0时，消除指向自身的引用，从而有向边总是指向0以上
                2. 对i>1，先从j=0，到j=i-1，替换每个i->j的边，每次都将得到j+1以上的边；因此，当j==i-1的时候，i将只有i以上的边；此时再消除i->i的引用，将只剩下指向右边的边
            + 在左递归文法这里，所谓i->j的边，其实是Ni -> Nj xxx，即，产生式右边的第1个位置的非终结符号，构成一条边。我们要做的就是，反复展开右边的Nj，使得右边的序号增大，直到右边只剩下i以上的非终结符好，最后再利用消除直接左递归的手法，消除i->i的引用。over
                + 这里消除直接左递归引入的新符号，不会形成左递归
    + 提取左因子(left factoring)
        + 提取左因子，使得基于预测的高效Parser成为可能
        + 形如，A-> L R1| L R2| C1 | C2，改写成 A-> L N | C1 |C2，N->R1 | R2
    + 为了减少回溯，甚至不回溯，给出Backtrack-free grammar(Predicate grammar)的定义(对应的Parser，叫Predicative Parser)
        + 首先是FirstSet: 给定终结符/非终结符，返回它的第1个终结符集合
            + 终结符(包括EOF和Empty)，其FirsetSet是自身
            + 非终结符的FirstSet，通过不动点算法来求
                + 当任意非终结符的FirstSet仍然在变化的时候，继续迭代
                + 非终结符N的FirstSet是其各个产生式右边符号序列的FirstSet的并，即FirstSet(N) = FirstSet(p1.body) | FirstSet(p2.body) | ...
                + 符号序列seq的FirstSet定义为，(FS(s1) - Empty) | (FS(s2) - Empty) | ... FS(sn)，这里，s1 s2 .. sn是seq的一个前缀，sn是第1个FirstSet不包含Empty的符号
        + 然后是FollowSet: 给定非终结符，返回它之后可能出现的终结符
            + 仍然是不同点算法
                + 对产生式p，它的定义是N -> A1 A2 ... An。初始化 tail=FollowSet(N)，从右到左迭代；如果Ai是终结符，则tail=FirstSet(Ai)；如果Ai是非终结符，先FollowSet(Ai) |= tail，然后，如果FirstSet(Ai)包括Empty，则tail |= FirstSet(Ai)，否则tail = FirstSet(Ai)
        + 最后是First+Set: 给定产生式，返回它可能的第1个终结符
            + 如果FirstSet(p.body)包含Empty，则First+Set是FirstSet(p.body) | FollowSet(p.nonTerm)，否则First+Set等于FirstSet(p.body)
        + 所谓Backtrack-free grammar，是指，文法中，对任意非终结符N，它的任意两个产生式，其First+Set不相交
            + 因此，当开始Parse非终结符N时，给定输入终结符T，总是能唯一的确定产生式，从而避免回溯
            + 即使文法不是LL1的，Predicate信息仍然能用来优化Top-down parser的性能；当然，由于需要有回溯逻辑，会比LL1 Parser慢
            + ANTLR实现了LL(k)算法
    + 没有算法能保证将任意CFG改写成LL1，但是，一般通过左递归消除、提取左因子，我们能得到LL1，或者接近LL1；前者能得到高效的无回溯Parser，后者的Predicate信息可用于提高回溯Parser的性能
    + 常见的Topdown-parsing方案包括
        + 回溯Parser
            + 注意要确保成功，应该支持非确定性Parse，这意味着，parse函数的返回应该是序列
            + Parser combinator
                + 性能取决于library的2次处理
                + 左递归
                    + 手工改写直接左递归为EBNF的rep
                    + 小心避免间接左递归
                + 回溯
                    + 手工提取左因子
                    + 尽量写成LL1的，否则开销是指数的
                + 错误处理
                    + 当不是LL1的时候，失败回溯可能不容易做(当需要到兄弟节点的子孙去回溯的时候)
            + Top-down parser: 
                + 可以递归或通过状态栈来迭代
                + 写成非确定性递归，比如，parse的返回值是Stream[Result]
                + 很容易通过First/Follow算法整合向前看信息，即使文法不是LL1的，也可以减少回溯的分支数，从而提高性能
            + 手工递归下降(hand-code recursive descent parsing)
                + 优点是是可以实施各种优化手段，比如不同的非终结符采用不同的LL(k)向前看
                + 缺点是要为每个编译器编写递归主体
        + LL1 Parser
            + 手工递归下降
                + 先处理文法(或者找源语言已有的LL1文法)：G -> 消除直接、间接左递归 -> 提取左公因子 -> 计算First+Set，最后提供每个产生式的预测符号给编码者
                + 每个非终结符内部都可以进行细节调优
            + Table driven LL1 Parser
                + G -> remove left recursion -> left factoring -> Map[NonTerm, Map[Term, Production]]，最后编写Parser主体(递归/迭代)，根据Predicate table来选择产生式
            + Direct code LL1 Parser
                + 根据Predicate table生成一组递归调用的函数
        + LL(k) Parser
            + ANTLR
+ 自底向上语法分析(Bottom-up parsing)
    + 推导，是从开始符号，经历一系列句型，最终得到语句的过程。推导的过程是Top-down的，因此，Bottom-up，就是推导的逆过程，即，从语句开始，经历一系列句型得到开始符号。Top-down过程，每次选择最左的产生式进行rewrite，因此是Leftmost derivation；而Bottom-up过程，由于输入单词流，是从左到右的，每次需要归约当前符号串，所以，相当于reversed rightmost derivation。
    + Top-down parser，是从开始符号往下完成Parse tree，任何时候，栈上保存的是部分完成的Parse tree的下边缘；Bottom-up parser，是从单词流往上完成Parse tree，任何时候，栈中保存的是部分完成的Parse tree的上边缘。
    + LR(0)乃至LR(k)，识别的上下文无关语言是一样大的，只是接受的文法不同，k越大，接受的文法越多，而k越小，则要求文法编写者以更复杂的方式提供文法。
    + 判断一个文法是否是LR的，最简单的办法是构建LR Parser，看是否产生Shift-reduce或者Reduce-reduce冲突。
    + 术语
        + Handle(句柄): 由产生式p和位置k一起构成了一个句柄。(A->B, k)，意思是，在LR语法分析器的累积状态k处，进行一次A->B的归约，得到的新的句型(由累积状态作为前缀，还未接受的单词流作为后缀)是有效推导的句型序列的一部分
        + Shift(移入): 把输入单词流中的下一个单词放入累积符号栈中，并更新DFA状态
        + Reduce(归约): 将当前累积符号栈的栈顶符号序列，重写为一个非终结符，并更新DFA状态
        + Reduce-reduce conflict: 下一个单词，导致的归约有多个，不确定应该执行哪个操作。Ambiguity grammar
        + Shift-reduce conflict: 下一个单词，既可以移入，也可以归约。Ambiguity grammar
        + LR0 item(LR0 项): 由产生式，及当前位置构成。当前位置的取值是0~p.body.length
            + 根据位置的情况，项可能分三种：
                1. Possibility: 可能的，pos == 0
                2. Complete: 完成的。可归约，pos == p.body.length
                3. Partially complete: 部分完成的。pos > 0 && pos < p.body.length
        + LR1 item(LR1 项): LR0 item的基础上，加上一个Lookahead符号(终结符)
        + Core LR1 item: 开始符号的所有项，或者非开始符号的位置>0的项
            + 所有非核心项，都可以从核心项closure出来。所谓closure操作，即，如果位置pos后紧接一个非终极符，那么，将它的所有Possibility项加入集合，递归该过程直到不动点
        + set of LR1 items: LR1 item的集合。因为LR parser的状态机，本质上是支持递归的DFA，所以如果把LR1 item看做NFA状态，那么，set of LR1 items就是LR1 item的配置，对应DFA状态
        + Canonical collection of sets of LR1 items: LR1项集的规范簇。看做整个DFA
    + LR语法分析器算法
        1. 准备Action表
            + Action表是2维表，第1维输入是状态号，第2维输入是终结符
            + 查表结果有三种
                1. Reduce p: 表示归约产生式p
                2. Shift j: 移入当前符号，并转移到状态j。DFA查询
                3. Accept: 当前输入合法。输入流应该只剩下List(Eof)
        2. 准备Goto表
            + Goto表是2维表，第1维输入是状态号，第2维是非终结符
            + 查表结果是另一个状态号，表示归约的结果。这里也是DFA查询
        3. 算法
            1. 准备状态栈和符号栈，状态栈用于支持递归的DFA句柄查找，符号栈用于根据语义动作(Semantic action)聚合结果，输出CST、AST等
            2. 将初始状态入栈
            3. 查询Action表，Action(stateStack.top, scanner.top)，差别结果：
                + Shift j: 将输入token压入符号栈，将DFA转移的目标状态j压入状态栈，递归
                + Reduce p: 从符号栈弹出p.body个符号并执行语义动作然后压栈；从状态栈弹出p.body个状态，然后查Goto(stateStack.top, p.nonTerm)并压入状态栈，递归
                + Accept: 如果输入只剩下List(Eof)，则语言识别成功，将此时符号栈上的结果输出
        + 本质上，LR算法其实是通过DFA来查找句柄，只不过通过栈引入了递归逻辑；每次归约的时候，从栈上弹出产生式的body，恢复DFA的上一个状态，然后根据归约的NonTerm继续进行DFA查找
            + 之所以可以通过DFA查找句柄，是因为，由句柄的集合构成的语言，是有限的，而有限的语言，总是可以通过DFA描述
    + Action、Goto表的构建算法
        + 公共步骤，构建DFA：从开始符号的0位置项集出发，closure过后，遍历所有终结符/非终结符，move(set, symbol)得到各个衍生核心项集。这里的每个核心项集，是一个DFA状态。
        + LR(0): 没有向前看符号。先构建DFA后，可以开始构建Action、Goto表。每个DFA状态之间的NonTerm迁移，添到Goto表中作为一项。Term迁移，作为Action表中的Shift动作。如果一个项集，有Term迁移，同时也有归约项，则构成Shift-reduce conflict，如果有多个归约项，则构成Reduce-reduce conflict。一般处理成，Term边构成Shift，非Term边一律Reduce
            + DFA状态少，容易conflict
            + 每个DFA状态，一旦有多个Reduce项、或者同时有Reduce项和Term边，都conflict。因此接受的文法少
        + SLR: 在LR0的基础上，对于有Reduce项的项集，只以其产生式左边的NonTerm的FollowSet作为向前看符号，因此，允许单一DFA状态有多个Reduce项或同时有Term项，只要FollowSet不想交，都不构成conflict
            + DFA状态少。和LR(0)状态数一样
            + Reduce的FollowSet相交(或者与Term边相交)才构成conflict。因此接收的文法比LR(0)大
        + LALR: 先构建DFA。对于每个项集(DFA状态)中的项(表示为项集号+项)，计算它的自生成向前看符号，以及它和其他项的传播关系，然后用不动点的方式，传播向前看符号。最终DFA中的每个状态的项，都带有一个向前看符号集合，这个集合是FollowSet的子集，因此允许的文法比SLR大
            + 自生成向前看符号和传播关系
                + 对于核心项(p, pos)，以SPECIAL_TERM为向前看符号计算closure并move，如果一个target项，以SPECIAL_TERM为向前看符号，则原始项和target项构成传播关系；否则，产生的lookAhead作为target项的自生成符号，用于将来的传播
            + DFA状态少。和LR(0)状态数一样
            + 通过生成、传播的方式构造每个项的向前看符号集，因为它总是FollowSet的子集，所以conflict更少，接收的文法范围更大(注意LR parse接收的语言都一样)
        + LR(1): 以带Lookahead的开始项，构建DFA。最后Reduce的时候，以自带的Lookahead作为向前看符号
            + DFA状态多，因为Lookahead将区别不同的核心项集。状态多，因此更少的conflict，接收更大的文法；但同时空间开销大，C语言的Parser对应的LALR只需要数百状态，LR1需要数千状态
            + 每个Reduce的Lookahead集合更精确，是LALR传播生成的Term集合子集，所以更少冲突
                + 构造LALR的另外一种方法，是先构造LR(1)，然后合并所有LR0部分相同的LR1项集，向前看符号取并集。这里的合并，不会产生Shift-reduce conflict，但是会产生Reduce-reduce conflict，这也说明LALR接收的文法比LR1小
    + Bottom-up parser类型
        + Table driven LR parser: LR Parser的标准算法
        + Direct code LR parser: 根据Action、Goto表生成代码。以代码的方式模拟带递归的DFA
+ 实践中的问题(Practical issues)
    + Error recovery
        + 由于ide等工具的需要，编译器应该能一次parse反馈尽量多的错误
        + 一种做法是，通过synchronizing word来同步parser状态
            + LL1 parser：发现错误后(调用中抛出的异常)，忽略一系列输入，直到发现对应当前NonTerm帧的同步单词，然后从当前NonTerm帧返回代表错误的语法树
            + LR1 parser: 发现错误后，忽略输入直到找到同步单词，然后连续弹出状态栈，直到发现某个状态存在Goto[s, NonTerm]，于是压栈Goto项，当做Parse成功(得到是错误语法树)
            + 常用的同步单词是“;”、“}”等
    + Unary operator
        + 添加一元运算符要谨慎
    + Handing context-sensitive ambiguity
        + 比如，在C语言中，如果不通过[]和()区分数组访问和函数调用的话，那么，由于无法区分Factor中的`array-ident ( opt-exp-list )`与`function-ident ( opt-exp-list )`，必然导致歧义
            + 可以在CFG中合并两个产生式，然后在语义分析中通过类型来区分
            + 也可以将类型信息通过符号表反馈给Scanner，然后Scanner对不同类型的ident分别输出array-ident、function-ident等
    + Left recursion versus Right recursion
        + Top-down parser只能右递归，没得选(需要的话，必须将直接/间接左递归转换成右递归)
        + 对于Bottom-up的LR parser来说，左递归、右递归都是允许的
            + 左递归的状态栈深度固定，边移入边归约；而右递归对栈的需求是线性的，只有移入所有子节点后，才进行连续的归约
            + 无论左递归还是右递归，显然语义不能破坏，比如结合性
+ 高级主题
    + 优化文法(Optimizing a grammar)
        + 如果能改写文法，使得推导的语法树高度减小，那么，对于LL parser来说，意味着更少的递归调用；对LR来说，意味着更少的Reduce(显然Shift次数不会变，恒等于输入流长度)，那么，性能会有所提高
        + 减少语法树层次的一种方法是，将useless production(即其右边只有一个符号的产生式)代入到每个引用中，这将减小最终语法树的层次。但由于产生式代换有可能导致产生式总数目增加，对LR parser来说，意味着更多的状态，所以反而有可能降低性能(对dcache不友好)；而如果是LL parser，可以通过人工调整代码，稍微弥补产生式数量增加带来的开销
    + 压缩LR1表
        + 分别压缩Action表和Goto表，使得相同的行/列被合并，在每次查表之前，经过一个`状态->行号`、`符号->列号`的映射
        + 在文法上面，合并引用相同的终结符号
        + 将Table driven parser改为Direct code parser，后者将不再处理空的单元格。同时由于避免了循环(label+goto)，通过适当调整代码排布，有可能得到更好的icache亲和性
        + 如果语言足够简单，不容易conflict的话，考虑SLR、LALR，他们的状态数和LR0一样
